{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2PdIposbViyARA5NlJ6BR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaanashri/CovidVision-Advanced-COVID-19-Detection-from-Lung-X-rays-with-Machine-Learning-or-Deep-Learnings/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwIf-gSVbcRK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Training And Testing Dataset\n"
      ],
      "metadata": {
        "id": "BSp0tw7ib1tj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Preprocessing\n"
      ],
      "metadata": {
        "id": "GHc6P7PkjWmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "dYKF5aGijXtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "CKn6rsXMjZ_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "8tSQ4UhujzYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn"
      ],
      "metadata": {
        "id": "_4KIv8vGj3zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# or\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "kUMh9srTj8sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library(dplyr)\n"
      ],
      "metadata": {
        "id": "IOLaAB6ukEHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library(data.table)\n"
      ],
      "metadata": {
        "id": "1Vn_3rG9kNUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library(caret)\n"
      ],
      "metadata": {
        "id": "G73Ymyv_kT9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tbPenmLwkurL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure ImageDataGenerator Class\n"
      ],
      "metadata": {
        "id": "bvZWpLmvk1i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values between 0 and 1\n",
        "    rotation_range=20,  # Randomly rotate images by 20 degrees\n",
        "    width_shift_range=0.2,  # Randomly shift images horizontally by 20% of the width\n",
        "    height_shift_range=0.2,  # Randomly shift images vertically by 20% of the height\n",
        "    shear_range=0.2,  # Apply random shear transformation\n",
        "    zoom_range=0.2,  # Apply random zoom transformation\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Fill any newly created pixels during transformations with the nearest pixel value\n",
        ")\n"
      ],
      "metadata": {
        "id": "RTcBtPuWk5et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "94gj537_k81b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply ImageDataGenerator Functionality To Train Set And Test Set\n"
      ],
      "metadata": {
        "id": "XLFtbn5ulWap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator with desired augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Path to the directory containing training images\n",
        "train_dir = 'path/to/training/directory'\n",
        "\n",
        "# Path to the directory containing testing images\n",
        "test_dir = 'path/to/testing/directory'\n",
        "\n",
        "# Generate augmented images for training set\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),  # Reshape images to this size\n",
        "    batch_size=32,\n",
        "    class_mode='binary'  # Set appropriate class_mode based on your dataset\n",
        ")\n",
        "\n",
        "# Generate augmented images for test set (without augmentation)\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "TsZu-ayylbPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "TjUyt1tHl-DF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create a sequential model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=10)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "# Make predictions on new data\n",
        "predictions = model.predict(new_data)\n"
      ],
      "metadata": {
        "id": "44GwPTB1mDEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pre-Trained CNN Model As A Feature Extractor"
      ],
      "metadata": {
        "id": "aNWS0YpumJgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the pre-trained model (VGG16 in this example)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the pre-trained model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create an instance of ImageDataGenerator for data preprocessing\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Path to the directory containing your data\n",
        "data_dir = 'path/to/data/directory'\n",
        "\n",
        "# Generate features for the training set\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Ensure the order of samples is preserved\n",
        ")\n",
        "\n",
        "# Extract features for the training set using the pre-trained model\n",
        "train_features = base_model.predict(train_generator)\n",
        "\n",
        "# Generate features for the test set\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Extract features for the test set using the pre-trained model\n",
        "test_features = base_model.predict(test_generator)\n",
        "\n",
        "# Now you can use the extracted features as input for a new model or task\n",
        "# For example, you can add a new classifier on top of the extracted features\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=train_features.shape[1:]))\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile and train the new model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_features, train_generator.labels, epochs=10)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_features, test_generator.labels)\n",
        "\n",
        "# Make predictions on new data\n",
        "new_data_features = base_model.predict(new_data_generator)\n",
        "predictions = model.predict(new_data_features)\n"
      ],
      "metadata": {
        "id": "HXmfHGnDma4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Dense Layers"
      ],
      "metadata": {
        "id": "a0r3Bse2mfTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Create a new model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a flatten layer to convert the extracted features to a 1D tensor\n",
        "model.add(Flatten(input_shape=train_features.shape[1:]))\n",
        "\n",
        "# Add dense layers\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Dropout layer to prevent overfitting\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add the final output layer with appropriate activation based on your task\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_features, train_labels, epochs=10)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_features, test_labels)\n",
        "\n",
        "# Make predictions on new data\n",
        "new_data_features = base_model.predict(new_data_generator)\n",
        "predictions = model.predict(new_data_features)\n"
      ],
      "metadata": {
        "id": "OFMkKyXXmnui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Configure The Learning Process"
      ],
      "metadata": {
        "id": "Wodsr_MAmykN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create an instance of the optimizer with the desired learning rate\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Create an instance of the loss function\n",
        "loss_function = BinaryCrossentropy()\n",
        "\n",
        "# Compile the model with the optimizer and loss function\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
        "\n",
        "# Train the model with custom configuration\n",
        "model.fit(train_features, train_labels, epochs=10, batch_size=32, validation_data=(val_features, val_labels))\n"
      ],
      "metadata": {
        "id": "WGhuQWqwnIPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train The Model"
      ],
      "metadata": {
        "id": "n-Re09zhna6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=10, batch_size=32, validation_data=(val_features, val_labels))\n"
      ],
      "metadata": {
        "id": "u1LbU1RTniqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_features, train_labels, epochs=10, batch_size=32, validation_data=(val_features, val_labels))\n",
        "\n",
        "# Access the training history\n",
        "print(history.history.keys())\n",
        "\n",
        "# Plot the training and validation loss over epochs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()\n",
        "\n",
        "# Plot the training and validation accuracy over epochs\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tPY98SdmoDQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Testing The Model"
      ],
      "metadata": {
        "id": "VQx9bsDKoGHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_features, test_labels)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_accuracy)\n"
      ],
      "metadata": {
        "id": "9uMX8JfVoPEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save The Model"
      ],
      "metadata": {
        "id": "4oBW-JD9oT75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('path/to/save/model.h5')\n"
      ],
      "metadata": {
        "id": "yQzWw87sopUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model('path/to/save/model.h5')\n"
      ],
      "metadata": {
        "id": "C9LfvbaEor2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Application Building"
      ],
      "metadata": {
        "id": "yMhJv-CipA3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Building Html Pages"
      ],
      "metadata": {
        "id": "XHKhSlprpDEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>My Web Page</title>\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            margin: 0;\n",
        "            padding: 20px;\n",
        "        }\n",
        "        \n",
        "        h1 {\n",
        "            color: #333;\n",
        "        }\n",
        "        \n",
        "        p {\n",
        "            color: #666;\n",
        "            line-height: 1.5;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Welcome to My Web Page</h1>\n",
        "    <p>This is a paragraph of text.</p>\n",
        "    <p>Here's another paragraph.</p>\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "IgVYIXmmpcVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Build Python Code"
      ],
      "metadata": {
        "id": "6efWRP03pgek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the numbers\n",
        "num1 = 5\n",
        "num2 = 3\n",
        "\n",
        "# Calculate the sum\n",
        "sum = num1 + num2\n",
        "\n",
        "# Print the result\n",
        "print(\"The sum is:\", sum)\n"
      ],
      "metadata": {
        "id": "087VKmX_qHfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "$ python sum.py\n"
      ],
      "metadata": {
        "id": "wbm4PO-7qNef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The sum is: 8\n"
      ],
      "metadata": {
        "id": "38rn47SiqV-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run The Application"
      ],
      "metadata": {
        "id": "akLVeT1BqXo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd Desktop/myapp\n"
      ],
      "metadata": {
        "id": "phAXcxT1qhw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python myapp.py\n"
      ],
      "metadata": {
        "id": "A2AhIOuFqnh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python --version\n"
      ],
      "metadata": {
        "id": "tQV9-d00qsfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train The Model On IBM"
      ],
      "metadata": {
        "id": "DiUz8uElrOHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Register For IBM Cloud"
      ],
      "metadata": {
        "id": "bgA_dTgKrjWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Too many requests / rate limit exceeded.."
      ],
      "metadata": {
        "id": "2lyVdFebr35E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model On IBM Watson Studio"
      ],
      "metadata": {
        "id": "R8XxUaB-sE0O"
      }
    }
  ]
}